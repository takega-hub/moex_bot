# Обучение ML моделей для Tinkoff бота

## Обзор

Система обучения моделей полностью адаптирована из криптобота и работает аналогично. Модели обучаются на исторических данных из CSV файлов.

## Компоненты

- **`bot/ml/model_trainer.py`**: Модуль для обучения моделей (RandomForest, XGBoost, LightGBM, Ensemble)
- **`bot/ml/feature_engineering.py`**: Создание технических индикаторов и фичей
- **`train_models.py`**: Скрипт для запуска обучения

## Запуск обучения

### Базовый запуск

```bash
python train_models.py
```

**Важно:** Скрипт автоматически обновляет исторические данные перед обучением, чтобы использовать актуальные данные.

Обучает модели для всех инструментов из `.env` (или по умолчанию: VBH6, SRH6, GLDRUBF)

### Обучение для конкретного инструмента

```bash
python train_models.py --ticker VBH6
```

### Обучение БЕЗ MTF фичей (только 15min)

```bash
python train_models.py --no-mtf
```

### Обучение с MTF фичами (1h, 4h)

```bash
python train_models.py --mtf
```

### Обучение на другом таймфрейме

```bash
python train_models.py --interval 1hour
```

### Пропуск обновления данных

Если данные уже актуальны и нужно пропустить обновление:

```bash
python train_models.py --skip-update
```

### Настройка периода обновления данных

По умолчанию обновляется 180 дней истории. Можно изменить:

```bash
python train_models.py --update-days 365
```

## Что делает скрипт

1. **Обновление данных** (автоматически, если не указан `--skip-update`):
   - Проверяет наличие данных для всех инструментов
   - Собирает недостающие исторические данные (по умолчанию 180 дней)
   - Обновляет данные до текущего момента
   - Если включены MTF фичи, обновляет данные для всех нужных интервалов (базовый + 1h, 4h)
2. **Загрузка данных**: Загружает исторические свечи из CSV файлов (`ml_data/`)
3. **Feature Engineering**: Создает технические индикаторы (RSI, MACD, ATR, Bollinger Bands и т.д.)
4. **MTF фичи** (опционально): Добавляет фичи с высших таймфреймов (1h, 4h)
5. **Создание таргета**: Создает целевую переменную (LONG=1, SHORT=-1, HOLD=0) на основе будущего движения цены
5. **Обучение моделей**: Обучает:
   - Random Forest
   - XGBoost (если установлен)
   - Ensemble (RF + XGBoost)
6. **Сохранение**: Сохраняет модели в `ml_models/` с метаданными

## Структура сохраненных моделей

Модели сохраняются в формате:
- `rf_{TICKER}_{INTERVAL}_{MODE}.pkl` - Random Forest
- `xgb_{TICKER}_{INTERVAL}_{MODE}.pkl` - XGBoost
- `ensemble_{TICKER}_{INTERVAL}_{MODE}.pkl` - Ensemble

Где:
- `TICKER` - тикер инструмента (VBH6, SRH6 и т.д.)
- `INTERVAL` - базовый интервал (15, 60 и т.д.)
- `MODE` - режим (15min, mtf_15min, mtf_1h и т.д.)

## Пример вывода

```
================================================================================
ОБУЧЕНИЕ ML МОДЕЛЕЙ ДЛЯ TINKOFF БОТА
================================================================================
Инструменты: VBH6, SRH6, GLDRUBF
Таймфрейм: 15min
MTF: Выключено
================================================================================

================================================================================
ОБУЧЕНИЕ МОДЕЛИ ДЛЯ VBH6
================================================================================

[1/5] Загрузка данных для VBH6...
Загружено 2500 свечей

[2/5] Создание признаков для VBH6...
Создано 85 признаков

[3/5] Создание целевой переменной...
Распределение классов:
  LONG :   450 (18.0%)
  SHORT:   380 (15.2%)
  HOLD :  1670 (66.8%)

[4/5] Подготовка данных для обучения...
Данные подготовлены: 2500 samples × 85 features

[5/5] Обучение моделей...
Веса классов:
  LONG: 2.50
  SHORT: 2.50
  HOLD: 0.30

Обучение Random Forest...
[model_trainer] Training Random Forest Classifier...
  Samples: 2500, Features: 85
  Class distribution: [380 1670 450]
[model_trainer] Training completed:
  Accuracy: 0.7520
  CV Accuracy: 0.7340 (+/- 0.0240)
Сохранено: rf_VBH6_15_15min.pkl
Accuracy: 0.7520
CV Accuracy: 0.7340 ± 0.0240

Обучение XGBoost...
[model_trainer] Training XGBoost Classifier...
  Samples: 2500, Features: 85
[model_trainer] Training completed:
  Accuracy: 0.7680
  CV Accuracy: 0.7510 (+/- 0.0280)
Сохранено: xgb_VBH6_15_15min.pkl
Accuracy: 0.7680
CV Accuracy: 0.7510 ± 0.0280

Обучение Ensemble (RF + XGBoost)...
[model_trainer] Training Ensemble Model (weighted_average)...
  Samples: 2500, Features: 85
  Class distribution: Counter({0: 1670, 1: 450, -1: 380})
  Ensemble weights: RF=0.494, XGB=0.506
Сохранено: ensemble_VBH6_15_15min.pkl
CV Accuracy: 0.7520 ± 0.0260

Обучение для VBH6 завершено!
```

## Требования

- Данные должны быть собраны в `ml_data/` (используйте `collect_historical_data.py`)
- Минимум 1000 свечей для качественного обучения
- Рекомендуется 2000-3000 свечей

## Настройка параметров обучения

Параметры можно изменить в `train_models.py`:

- `n_estimators`: Количество деревьев (по умолчанию: 100)
- `max_depth`: Максимальная глубина дерева (по умолчанию: 10 для RF, 6 для XGBoost)
- `forward_periods`: Период для создания таргета (по умолчанию: 5 для 15min, 2 для 1hour)
- `threshold_pct`: Минимальный процент движения для сигнала (по умолчанию: 0.3%)

## Использование обученных моделей

Обученные модели автоматически используются ботом при запуске (`run_bot.py`). Бот ищет модели в `ml_models/` по паттерну `*_{TICKER}_*.pkl`.
