"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –º–∞—Å—Å–æ–≤–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –í–°–ï–• ML –º–æ–¥–µ–ª–µ–π –ø–æ –∫–∞–∂–¥–æ–º—É –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—É.

–ó–∞–ø—É—Å–∫–∞–µ—Ç –±—ç–∫—Ç–µ—Å—Ç –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ ml_models –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç —Å–≤–æ–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É.
"""
import argparse
import os
import sys
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from functools import partial
import concurrent.futures
import traceback

import pandas as pd
import numpy as np
from tqdm import tqdm

try:
    from backtest_ml_strategy import run_exact_backtest, BacktestMetrics
except ImportError as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
    sys.exit(1)


def find_all_tickers(models_dir: Path) -> List[str]:
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞—Ö–æ–¥–∏—Ç –≤—Å–µ —Ç–∏–∫–µ—Ä—ã –∏–∑ –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤ –º–æ–¥–µ–ª–µ–π."""
    if not models_dir.exists():
        return []
    
    tickers = set()
    
    for model_file in models_dir.glob("*.pkl"):
        name = model_file.stem
        parts = name.split("_")
        
        if len(parts) >= 2:
            for part in parts[1:]:
                part_upper = part.upper()
                if len(part_upper) >= 3 and part_upper.isalnum():
                    tickers.add(part_upper)
                    break
    
    return sorted(list(tickers))


def find_models_for_ticker(models_dir: Path, ticker: str) -> List[Path]:
    """–ò—â–µ—Ç –≤—Å–µ ML –º–æ–¥–µ–ª–∏ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —Ç–∏–∫–µ—Ä–∞."""
    if not models_dir.exists():
        return []
    
    patterns = [
        f"*_{ticker}_*.pkl",
        f"*{ticker}*.pkl",
    ]
    
    results: List[Path] = []
    for pattern in patterns:
        for f in models_dir.glob(pattern):
            if f.is_file() and f not in results:
                results.append(f)
    
    return sorted(list({f.resolve() for f in results}))


def extract_interval_from_model(model_path: Path) -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ç–µ—Ä–≤–∞–ª –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –º–æ–¥–µ–ª–∏."""
    name = model_path.stem
    parts = name.split("_")
    
    for part in parts:
        if part in ["15", "60", "240", "D"]:
            return part
    
    return "15"


def metrics_to_dict(m: BacktestMetrics, model_path: Path) -> Dict[str, Any]:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç BacktestMetrics –≤ —Å–ª–æ–≤–∞—Ä—å."""
    if m is None:
        return {}
    
    filename = model_path.name
    name_no_ext = filename.replace(".pkl", "")
    parts = name_no_ext.split("_")
    
    model_type = parts[0] if parts else "unknown"
    mode_suffix = None
    if len(parts) >= 4:
        mode_suffix = parts[-1]
    
    result = {
        "ticker": m.ticker,
        "model_name": m.model_name,
        "model_filename": filename,
        "model_path": str(model_path),
        "model_type": model_type,
        "mode_suffix": mode_suffix or "",
        "total_trades": m.total_trades,
        "winning_trades": m.winning_trades,
        "losing_trades": m.losing_trades,
        "win_rate_pct": m.win_rate,
        "total_pnl_rub": m.total_pnl,
        "total_pnl_pct": m.total_pnl_pct,
        "profit_factor": m.profit_factor,
        "max_drawdown_rub": m.max_drawdown,
        "max_drawdown_pct": m.max_drawdown_pct,
        "sharpe_ratio": m.sharpe_ratio,
        "long_trades": m.long_signals,
        "short_trades": m.short_signals,
        "avg_win_rub": m.avg_win,
        "avg_loss_rub": m.avg_loss,
        "best_trade_rub": m.best_trade_pnl,
        "worst_trade_rub": m.worst_trade_pnl,
        "avg_confidence": m.avg_confidence,
        "avg_tp_distance_pct": m.avg_tp_distance_pct,
        "avg_sl_distance_pct": m.avg_sl_distance_pct,
        "avg_rr_ratio": m.avg_rr_ratio,
        "signals_with_tp_sl_pct": m.signals_with_tp_sl_pct,
        "signals_with_correct_sl_pct": m.signals_with_correct_sl_pct,
    }
    
    return result


def test_single_model(args_tuple: Tuple) -> Optional[Dict[str, Any]]:
    """–§—É–Ω–∫—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏ (–¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è)."""
    model_path, ticker, days, interval, initial_balance, risk_per_trade, leverage = args_tuple
    
    try:
        import matplotlib
        matplotlib.use('Agg')
        
        from backtest_ml_strategy import run_exact_backtest
        
        model_interval = extract_interval_from_model(model_path)
        test_interval = interval.replace("min", "").replace("hour", "60").replace("day", "D")
        if test_interval == "15" and model_interval != "15":
            test_interval = model_interval
        
        metrics = run_exact_backtest(
            model_path=str(model_path),
            ticker=ticker,
            days_back=days,
            interval=test_interval,
            initial_balance=initial_balance,
            risk_per_trade=risk_per_trade,
            leverage=leverage,
        )
        
        if metrics is None:
            return None
        
        return metrics_to_dict(metrics, model_path)
        
    except Exception as e:
        return {"error": True, "model": model_path.name, "message": str(e)[:100]}


def compare_models(
    tickers: List[str],
    models_dir: Path,
    days: int = 30,
    interval: str = "15min",
    initial_balance: float = 10000.0,
    risk_per_trade: float = 0.02,
    leverage: int = 1,
    workers: int = 4,
) -> pd.DataFrame:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –±—ç–∫—Ç–µ—Å—Ç –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏."""
    all_results: List[Dict[str, Any]] = []
    
    print("=" * 80)
    print("üöÄ ML MODELS COMPARISON BACKTEST (TINKOFF)")
    print("=" * 80)
    print(f"üìä Tickers: {', '.join(tickers)}")
    print(f"üìÅ Models dir: {models_dir}")
    print(f"‚öôÔ∏è  Days: {days}, Interval: {interval}")
    print(f"üí∞ Initial balance: {initial_balance:.2f} —Ä—É–±")
    print(f"üéØ Risk per trade: {risk_per_trade*100:.1f}%, Leverage: {leverage}x")
    print(f"‚ö° Workers: {workers}")
    print("=" * 80)
    
    all_models: List[Tuple[Path, str]] = []
    for ticker in tickers:
        models = find_models_for_ticker(models_dir, ticker)
        for model in models:
            all_models.append((model, ticker))
    
    if not all_models:
        print(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
        return pd.DataFrame()
    
    print(f"\nüì¶ –ù–∞–π–¥–µ–Ω–æ {len(all_models)} –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
    
    test_args = [
        (model_path, ticker, days, interval, initial_balance, risk_per_trade, leverage)
        for model_path, ticker in all_models
    ]
    
    print(f"\nüöÄ –ó–∞–ø—É—Å–∫ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è ({workers} workers)...")
    with concurrent.futures.ProcessPoolExecutor(max_workers=workers) as executor:
        results = list(tqdm(
            executor.map(test_single_model, test_args),
            total=len(test_args),
            desc="Testing models"
        ))
    
    for result in results:
        if result and not result.get("error", False):
            all_results.append(result)
        elif result and result.get("error", False):
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –≤ –º–æ–¥–µ–ª–∏ {result.get('model', 'unknown')}: {result.get('message', 'Unknown error')}")
    
    if not all_results:
        print(f"‚ùå –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è")
        return pd.DataFrame()
    
    df_results = pd.DataFrame(all_results)
    
    if "sharpe_ratio" in df_results.columns:
        df_results = df_results.sort_values("sharpe_ratio", ascending=False)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = f"ml_models_comparison_{timestamp}.csv"
    df_results.to_csv(output_file, index=False)
    print(f"\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_file}")
    
    print(f"\nüèÜ –¢–û–ü-10 –ú–û–î–ï–õ–ï–ô (–ø–æ Sharpe Ratio):")
    print("=" * 80)
    top_models = df_results.head(10)
    for idx, row in top_models.iterrows():
        print(f"{idx+1:2d}. {row['model_filename']:40s} | "
              f"Sharpe: {row['sharpe_ratio']:6.2f} | "
              f"PnL: {row['total_pnl_pct']:7.2f}% | "
              f"Trades: {row['total_trades']:4d} | "
              f"WR: {row['win_rate_pct']:5.1f}%")
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    print(f"\nüìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π...")
    analysis_text = generate_analysis_and_recommendations(df_results, output_file)
    print(analysis_text)
    
    return df_results


def generate_analysis_and_recommendations(df_results: pd.DataFrame, output_file: str) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –ø—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç–∏."""
    if df_results.empty:
        return ""
    
    analysis_lines = []
    analysis_lines.append("=" * 80)
    analysis_lines.append("üìä –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –ú–û–î–ï–õ–ï–ô")
    analysis_lines.append("=" * 80)
    analysis_lines.append("")
    
    # 1. –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    analysis_lines.append("1. –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    analysis_lines.append("-" * 80)
    total_models = len(df_results)
    profitable_models = len(df_results[df_results['total_pnl_pct'] > 0])
    avg_sharpe = df_results['sharpe_ratio'].mean()
    avg_win_rate = df_results['win_rate_pct'].mean()
    avg_pnl = df_results['total_pnl_pct'].mean()
    
    analysis_lines.append(f"   –í—Å–µ–≥–æ –º–æ–¥–µ–ª–µ–π: {total_models}")
    analysis_lines.append(f"   –ü—Ä–∏–±—ã–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π: {profitable_models} ({profitable_models/total_models*100:.1f}%)")
    analysis_lines.append(f"   –°—Ä–µ–¥–Ω–∏–π Sharpe Ratio: {avg_sharpe:.2f}")
    analysis_lines.append(f"   –°—Ä–µ–¥–Ω–∏–π Win Rate: {avg_win_rate:.1f}%")
    analysis_lines.append(f"   –°—Ä–µ–¥–Ω–∏–π PnL: {avg_pnl:.2f}%")
    analysis_lines.append("")
    
    # 2. –ê–Ω–∞–ª–∏–∑ –ø–æ —Ç–∏–ø–∞–º –º–æ–¥–µ–ª–µ–π
    analysis_lines.append("2. –ê–ù–ê–õ–ò–ó –ü–û –¢–ò–ü–ê–ú –ú–û–î–ï–õ–ï–ô")
    analysis_lines.append("-" * 80)
    model_type_stats = df_results.groupby('model_type').agg({
        'sharpe_ratio': ['mean', 'max', 'count'],
        'total_pnl_pct': ['mean', 'max'],
        'win_rate_pct': 'mean',
        'total_trades': 'mean'
    }).round(2)
    
    for model_type in df_results['model_type'].unique():
        type_df = df_results[df_results['model_type'] == model_type]
        if len(type_df) > 0:
            analysis_lines.append(f"   {model_type.upper()}:")
            analysis_lines.append(f"      –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ: {len(type_df)}")
            analysis_lines.append(f"      –°—Ä–µ–¥–Ω–∏–π Sharpe: {type_df['sharpe_ratio'].mean():.2f}")
            analysis_lines.append(f"      –õ—É—á—à–∏–π Sharpe: {type_df['sharpe_ratio'].max():.2f}")
            analysis_lines.append(f"      –°—Ä–µ–¥–Ω–∏–π PnL: {type_df['total_pnl_pct'].mean():.2f}%")
            analysis_lines.append(f"      –°—Ä–µ–¥–Ω–∏–π Win Rate: {type_df['win_rate_pct'].mean():.1f}%")
            analysis_lines.append(f"      –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª-–≤–æ —Å–¥–µ–ª–æ–∫: {type_df['total_trades'].mean():.0f}")
            analysis_lines.append("")
    
    # 3. –ê–Ω–∞–ª–∏–∑ –ø–æ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º
    analysis_lines.append("3. –ê–ù–ê–õ–ò–ó –ü–û –ò–ù–°–¢–†–£–ú–ï–ù–¢–ê–ú")
    analysis_lines.append("-" * 80)
    for ticker in df_results['ticker'].unique():
        ticker_df = df_results[df_results['ticker'] == ticker]
        if len(ticker_df) > 0:
            best_model = ticker_df.loc[ticker_df['sharpe_ratio'].idxmax()]
            analysis_lines.append(f"   {ticker}:")
            analysis_lines.append(f"      –ú–æ–¥–µ–ª–µ–π: {len(ticker_df)}")
            analysis_lines.append(f"      –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {best_model['model_filename']}")
            analysis_lines.append(f"      –õ—É—á—à–∏–π Sharpe: {best_model['sharpe_ratio']:.2f}")
            analysis_lines.append(f"      –õ—É—á—à–∏–π PnL: {best_model['total_pnl_pct']:.2f}%")
            analysis_lines.append(f"      –°—Ä–µ–¥–Ω–∏–π Win Rate: {ticker_df['win_rate_pct'].mean():.1f}%")
            analysis_lines.append("")
    
    # 4. –í—ã—è–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º
    analysis_lines.append("4. –í–´–Ø–í–õ–ï–ù–ù–´–ï –ü–†–û–ë–õ–ï–ú–´")
    analysis_lines.append("-" * 80)
    
    # –ü—Ä–æ–±–ª–µ–º–∞: –Ω–∏–∑–∫–∏–π Win Rate
    low_wr = df_results[df_results['win_rate_pct'] < 50]
    if len(low_wr) > 0:
        analysis_lines.append(f"   ‚ö†Ô∏è  –ù–∏–∑–∫–∏–π Win Rate (<50%): {len(low_wr)} –º–æ–¥–µ–ª–µ–π")
        for _, row in low_wr.iterrows():
            analysis_lines.append(f"      - {row['model_filename']}: WR={row['win_rate_pct']:.1f}%")
        analysis_lines.append("")
    
    # –ü—Ä–æ–±–ª–µ–º–∞: –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π PnL
    negative_pnl = df_results[df_results['total_pnl_pct'] < 0]
    if len(negative_pnl) > 0:
        analysis_lines.append(f"   ‚ùå –£–±—ã—Ç–æ—á–Ω—ã–µ –º–æ–¥–µ–ª–∏: {len(negative_pnl)}")
        for _, row in negative_pnl.iterrows():
            analysis_lines.append(f"      - {row['model_filename']}: PnL={row['total_pnl_pct']:.2f}%")
        analysis_lines.append("")
    
    # –ü—Ä–æ–±–ª–µ–º–∞: –º–∞–ª–æ —Å–¥–µ–ª–æ–∫
    few_trades = df_results[df_results['total_trades'] < 10]
    if len(few_trades) > 0:
        analysis_lines.append(f"   ‚ö†Ô∏è  –ú–∞–ª–æ —Å–¥–µ–ª–æ–∫ (<10): {len(few_trades)} –º–æ–¥–µ–ª–µ–π")
        for _, row in few_trades.iterrows():
            analysis_lines.append(f"      - {row['model_filename']}: {row['total_trades']} —Å–¥–µ–ª–æ–∫")
        analysis_lines.append("")
    
    # –ü—Ä–æ–±–ª–µ–º–∞: –Ω–∏–∑–∫–∏–π Profit Factor
    low_pf = df_results[df_results['profit_factor'] < 1.5]
    if len(low_pf) > 0:
        analysis_lines.append(f"   ‚ö†Ô∏è  –ù–∏–∑–∫–∏–π Profit Factor (<1.5): {len(low_pf)} –º–æ–¥–µ–ª–µ–π")
        analysis_lines.append("")
    
    # –ü—Ä–æ–±–ª–µ–º–∞: —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ TP/SL
    if 'avg_rr_ratio' in df_results.columns:
        wrong_rr = df_results[df_results['avg_rr_ratio'] < 2.0]
        if len(wrong_rr) > 0:
            analysis_lines.append(f"   ‚ö†Ô∏è  –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ TP/SL (<2.0): {len(wrong_rr)} –º–æ–¥–µ–ª–µ–π")
            analysis_lines.append(f"      –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ 2.5:1")
            analysis_lines.append("")
    
    # 5. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
    analysis_lines.append("5. –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –£–õ–£–ß–®–ï–ù–ò–Æ –ü–†–ò–ë–´–õ–¨–ù–û–°–¢–ò")
    analysis_lines.append("-" * 80)
    
    # –õ—É—á—à–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    top_3 = df_results.head(3)
    analysis_lines.append("   ‚úÖ –†–ï–ö–û–ú–ï–ù–î–£–ï–ú–´–ï –ú–û–î–ï–õ–ò –î–õ–Ø –ü–†–û–î–ê–ö–®–ï–ù–ê:")
    for idx, (_, row) in enumerate(top_3.iterrows(), 1):
        analysis_lines.append(f"      {idx}. {row['model_filename']}")
        analysis_lines.append(f"         Sharpe: {row['sharpe_ratio']:.2f}, PnL: {row['total_pnl_pct']:.2f}%, WR: {row['win_rate_pct']:.1f}%")
    analysis_lines.append("")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ç–∏–ø–∞–º –º–æ–¥–µ–ª–µ–π
    best_type = df_results.groupby('model_type')['sharpe_ratio'].mean().idxmax()
    analysis_lines.append(f"   üìà –õ–£–ß–®–ò–ô –¢–ò–ü –ú–û–î–ï–õ–ò: {best_type.upper()}")
    analysis_lines.append(f"      –°—Ä–µ–¥–Ω–∏–π Sharpe: {df_results[df_results['model_type'] == best_type]['sharpe_ratio'].mean():.2f}")
    analysis_lines.append("")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    analysis_lines.append("   üîß –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –ü–û –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò:")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è TP/SL
    if 'avg_rr_ratio' in df_results.columns:
        avg_rr = df_results['avg_rr_ratio'].mean()
        if avg_rr < 2.0:
            analysis_lines.append(f"      ‚Ä¢ –£–≤–µ–ª–∏—á–∏—Ç—å —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ TP/SL –¥–æ 2.5:1 (—Ç–µ–∫—É—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ: {avg_rr:.2f})")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ Win Rate
    if avg_win_rate < 60:
        analysis_lines.append(f"      ‚Ä¢ –£–ª—É—á—à–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è Win Rate (—Ç–µ–∫—É—â–∏–π: {avg_win_rate:.1f}%)")
        analysis_lines.append(f"        - –£–≤–µ–ª–∏—á–∏—Ç—å confidence_threshold")
        analysis_lines.append(f"        - –î–æ–±–∞–≤–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã (—Ç—Ä–µ–Ω–¥, –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å)")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–¥–µ–ª–æ–∫
    avg_trades = df_results['total_trades'].mean()
    if avg_trades < 20:
        analysis_lines.append(f"      ‚Ä¢ –£–≤–µ–ª–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–≥–Ω–∞–ª–æ–≤ (—Ç–µ–∫—É—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ: {avg_trades:.0f} —Å–¥–µ–ª–æ–∫)")
        analysis_lines.append(f"        - –°–º—è–≥—á–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞—Ä–≥–µ—Ç–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏")
        analysis_lines.append(f"        - –°–Ω–∏–∑–∏—Ç—å confidence_threshold")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ Profit Factor
    avg_pf = df_results['profit_factor'].mean()
    if avg_pf < 2.0:
        analysis_lines.append(f"      ‚Ä¢ –£–ª—É—á—à–∏—Ç—å —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –ø—Ä–∏–±—ã–ª—å/—É–±—ã—Ç–æ–∫ (—Ç–µ–∫—É—â–∏–π PF: {avg_pf:.2f})")
        analysis_lines.append(f"        - –£–ª—É—á—à–∏—Ç—å —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–∏—Å–∫–∞–º–∏")
        analysis_lines.append(f"        - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å trailing stop")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –º–æ–¥–µ–ª—è–º
    analysis_lines.append("")
    analysis_lines.append("   üéØ –ö–û–ù–ö–†–ï–¢–ù–´–ï –î–ï–ô–°–¢–í–ò–Ø:")
    
    # –î–ª—è —É–±—ã—Ç–æ—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
    if len(negative_pnl) > 0:
        analysis_lines.append(f"      ‚Ä¢ –ü–µ—Ä–µ–æ–±—É—á–∏—Ç—å {len(negative_pnl)} —É–±—ã—Ç–æ—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π:")
        analysis_lines.append(f"        - –£–≤–µ–ª–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
        analysis_lines.append(f"        - –ù–∞—Å—Ç—Ä–æ–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç–∞—Ä–≥–µ—Ç–∞ (forward_periods, threshold_pct)")
        analysis_lines.append(f"        - –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –¥—Ä—É–≥–∏–µ —Ç–∏–ø—ã –º–æ–¥–µ–ª–µ–π")
    
    # –î–ª—è –º–æ–¥–µ–ª–µ–π —Å –Ω–∏–∑–∫–∏–º Win Rate
    if len(low_wr) > 0:
        analysis_lines.append(f"      ‚Ä¢ –£–ª—É—á—à–∏—Ç—å {len(low_wr)} –º–æ–¥–µ–ª–µ–π —Å –Ω–∏–∑–∫–∏–º Win Rate:")
        analysis_lines.append(f"        - –ü–æ–≤—ã—Å–∏—Ç—å confidence_threshold")
        analysis_lines.append(f"        - –î–æ–±–∞–≤–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä—ã –ø–æ —Ç—Ä–µ–Ω–¥—É –∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏")
        analysis_lines.append(f"        - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–Ω—Å–∞–º–±–ª–∏ –≤–º–µ—Å—Ç–æ –æ–¥–∏–Ω–æ—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∞–Ω—Å–∞–º–±–ª—è–º
    ensemble_models = df_results[df_results['model_type'].isin(['ensemble', 'triple', 'quad'])]
    single_models = df_results[~df_results['model_type'].isin(['ensemble', 'triple', 'quad'])]
    
    if len(ensemble_models) > 0 and len(single_models) > 0:
        ensemble_avg_sharpe = ensemble_models['sharpe_ratio'].mean()
        single_avg_sharpe = single_models['sharpe_ratio'].mean()
        
        if ensemble_avg_sharpe > single_avg_sharpe:
            analysis_lines.append(f"      ‚Ä¢ –ê–Ω—Å–∞–º–±–ª–∏ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (Sharpe: {ensemble_avg_sharpe:.2f} vs {single_avg_sharpe:.2f})")
            analysis_lines.append(f"        - –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞–Ω—Å–∞–º–±–ª–∏ –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞")
        else:
            analysis_lines.append(f"      ‚Ä¢ –û–¥–∏–Ω–æ—á–Ω—ã–µ –º–æ–¥–µ–ª–∏ –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
            analysis_lines.append(f"        - –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—é –≤–µ—Å–æ–≤ –∞–Ω—Å–∞–º–±–ª–µ–π")
    
    analysis_lines.append("")
    analysis_lines.append("=" * 80)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ –≤ —Ñ–∞–π–ª
    analysis_text = "\n".join(analysis_lines)
    analysis_file = output_file.replace('.csv', '_analysis.txt')
    with open(analysis_file, 'w', encoding='utf-8') as f:
        f.write(analysis_text)
    
    return analysis_text


def main():
    parser = argparse.ArgumentParser(description='–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö ML –º–æ–¥–µ–ª–µ–π –¥–ª—è Tinkoff –±–æ—Ç–∞')
    parser.add_argument('--tickers', type=str, default='auto', help='–¢–∏–∫–µ—Ä—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (auto –¥–ª—è –∞–≤—Ç–æ–ø–æ–∏—Å–∫–∞)')
    parser.add_argument('--models-dir', type=str, default='ml_models', help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –º–æ–¥–µ–ª—è–º–∏')
    parser.add_argument('--days', type=int, default=30, help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –¥–ª—è –±—ç–∫—Ç–µ—Å—Ç–∞')
    parser.add_argument('--interval', type=str, default='15min', help='–ò–Ω—Ç–µ—Ä–≤–∞–ª —Å–≤–µ—á–µ–π')
    parser.add_argument('--balance', type=float, default=10000.0, help='–ù–∞—á–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å –≤ —Ä—É–±–ª—è—Ö')
    parser.add_argument('--risk', type=float, default=0.02, help='–†–∏—Å–∫ –Ω–∞ —Å–¥–µ–ª–∫—É')
    parser.add_argument('--leverage', type=int, default=1, help='–ü–ª–µ—á–æ')
    parser.add_argument('--workers', type=int, default=4, help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤')
    
    args = parser.parse_args()
    
    models_dir = Path(args.models_dir)
    
    if args.tickers.lower() == 'auto':
        tickers = find_all_tickers(models_dir)
        if not tickers:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ç–∏–∫–µ—Ä–æ–≤. –£–∫–∞–∂–∏—Ç–µ --tickers –≤—Ä—É—á–Ω—É—é.")
            sys.exit(1)
        print(f"üîç –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞–π–¥–µ–Ω—ã —Ç–∏–∫–µ—Ä—ã: {', '.join(tickers)}")
    else:
        tickers = [t.strip().upper() for t in args.tickers.split(",")]
    
    df_results = compare_models(
        tickers=tickers,
        models_dir=models_dir,
        days=args.days,
        interval=args.interval,
        initial_balance=args.balance,
        risk_per_trade=args.risk,
        leverage=args.leverage,
        workers=args.workers,
    )
    
    if df_results.empty:
        print(f"\n‚ùå –ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è")
        sys.exit(1)
    
    print(f"\n‚úÖ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print(f"   –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(df_results)}")
    print(f"   –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å: {df_results.iloc[0]['model_filename']}")


if __name__ == "__main__":
    main()
